{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data from database\n",
    "pandas vs blaze\n",
    "\n",
    "#### Task\n",
    "* query database just like using ORM without writing any SQL statements\n",
    "* do calc based on the return results\n",
    "* monitor the memory usage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### datasource\n",
    "single table in remote database\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. using blaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blaze import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blaze does not understand a SQLAlchemy type.\n",
      "Blaze provided the following error:\n",
      "\tNo SQL-datashape match for type BLOB\n",
      "Skipping.\n",
      "Blaze does not understand a SQLAlchemy type.\n",
      "Blaze provided the following error:\n",
      "\tNo SQL-datashape match for type BLOB\n",
      "Skipping.\n"
     ]
    }
   ],
   "source": [
    "DB_URL = \"mysql://%s:%s@%s:%s/%s::secret_txn_tab\" % ('secret')\n",
    "orders = Data(DB_URL)\n",
    "# noted the warning msg below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when I use blaze in production, I got `ValueError: Unsupported string encoding u'utf8mb4_unicode_ci` error.\n",
    "the target database using utf8mb4 charset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_by_date = orders[(orders.channelid==70000) & (orders.ctime>=1437840000) & (orders.ctime<1437926400)& (orders.status==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(order_by_date.count())\n",
    "\n",
    "# the count() method diff from pandas count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212018"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(order_by_date.amount.sum())/100000\n",
    "\n",
    "# same usage with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "209L"
      ],
      "text/plain": [
       "209L"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_by_date.userid.distinct().count()\n",
    "\n",
    "# pandas use drop_duplicates() instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_URL = \"mysql://%s:%s@%s:%s/%s\" % ('secret')\n",
    "engine = create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = pd.read_sql('select * from secret_txn_tab',\n",
    "                 con=engine)\n",
    "\n",
    "# using pandas still need to write the sql statement\n",
    "# can specify the columns you need in the select statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txnid</th>\n",
       "      <th>userid</th>\n",
       "      <th>refund_txnid</th>\n",
       "      <th>checkoutid</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>channelid</th>\n",
       "      <th>status</th>\n",
       "      <th>channel_status</th>\n",
       "      <th>channel_txnid</th>\n",
       "      <th>ip</th>\n",
       "      <th>action_country</th>\n",
       "      <th>ctime</th>\n",
       "      <th>vtime</th>\n",
       "      <th>mtime</th>\n",
       "      <th>memo</th>\n",
       "      <th>extra_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>11183</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>89000000</td>\n",
       "      <td>THB</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2224250195</td>\n",
       "      <td>SG</td>\n",
       "      <td>1432303352</td>\n",
       "      <td>0</td>\n",
       "      <td>1432303352</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>11184</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>59000000</td>\n",
       "      <td>THB</td>\n",
       "      <td>71000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td></td>\n",
       "      <td>3669652968</td>\n",
       "      <td>SG</td>\n",
       "      <td>1432307027</td>\n",
       "      <td>0</td>\n",
       "      <td>1432309356</td>\n",
       "      <td></td>\n",
       "      <td>{\"transfer_fields\": {\"name\": \"Liu jing\", \"memo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000002</td>\n",
       "      <td>11184</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>69000000</td>\n",
       "      <td>THB</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3669652968</td>\n",
       "      <td>SG</td>\n",
       "      <td>1432307426</td>\n",
       "      <td>0</td>\n",
       "      <td>1432307426</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000003</td>\n",
       "      <td>11184</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>69000000</td>\n",
       "      <td>THB</td>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4323108605155000001366</td>\n",
       "      <td>3669652968</td>\n",
       "      <td>SG</td>\n",
       "      <td>1432310801</td>\n",
       "      <td>1432310864</td>\n",
       "      <td>1432310864</td>\n",
       "      <td></td>\n",
       "      <td>{\"card_number\": \"426569xxxxxx3103\", \"auth_code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000004</td>\n",
       "      <td>11174</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>59000000</td>\n",
       "      <td>THB</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2088405459</td>\n",
       "      <td>TH</td>\n",
       "      <td>1432311210</td>\n",
       "      <td>0</td>\n",
       "      <td>1432311210</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     txnid  userid  refund_txnid  checkoutid  type    amount currency  \\\n",
       "0  1000000   11183             0          95     0  89000000      THB   \n",
       "1  1000001   11184             0         100     0  59000000      THB   \n",
       "2  1000002   11184             0         104     0  69000000      THB   \n",
       "3  1000003   11184             0         104     0  69000000      THB   \n",
       "4  1000004   11174             0         111     0  59000000      THB   \n",
       "\n",
       "   channelid  status  channel_status           channel_txnid          ip  \\\n",
       "0      70000       0               0                          2224250195   \n",
       "1      71000       0             200                          3669652968   \n",
       "2      70000       0               0                          3669652968   \n",
       "3      70000       1             100  4323108605155000001366  3669652968   \n",
       "4      70000       0               0                          2088405459   \n",
       "\n",
       "  action_country       ctime       vtime       mtime memo  \\\n",
       "0             SG  1432303352           0  1432303352        \n",
       "1             SG  1432307027           0  1432309356        \n",
       "2             SG  1432307426           0  1432307426        \n",
       "3             SG  1432310801  1432310864  1432310864        \n",
       "4             TH  1432311210           0  1432311210        \n",
       "\n",
       "                                          extra_data  \n",
       "0                                                 {}  \n",
       "1  {\"transfer_fields\": {\"name\": \"Liu jing\", \"memo...  \n",
       "2                                                 {}  \n",
       "3  {\"card_number\": \"426569xxxxxx3103\", \"auth_code...  \n",
       "4                                                 {}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_today = orders[(orders.channelid==70000) & (orders.ctime>=1437840000) & (orders.ctime<1437926400)& (orders.status==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_user = int(order_today.userid.drop_duplicates().count())\n",
    "total_user\n",
    "\n",
    "#len(order_today.userid.unique()) VS order_today.userid.drop_duplicates().count()\n",
    "#哪个更快？后面待测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_txn = int(order_today.txnid.count())\n",
    "total_txn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_amt = int(order_today.amount.sum()) / 500000\n",
    "total_amt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pandas vs blaze\n",
    "1. the API diffs refer to [blaze website](http://blaze.pydata.org/en/latest/rosetta-pandas.html)\n",
    "2. can be easily conver using odo or Data()\n",
    "3. Blaze can simplify and make more readable some common IO tasks that one would want to do with pandas. These examples make use of the odo library. In many cases, blaze will able to handle datasets that can’t fit into main memory, which is something that can’t be easily done with pandas.(but this time I got those charset problems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_size(df):\n",
    "    \"\"\"Return the size of a DataFrame in Megabyes\"\"\"\n",
    "    total = 0.0\n",
    "    for col in df:\n",
    "        total += df[col].nbytes\n",
    "    return total/1048576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9620513916015625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_size(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "txnid             21569\n",
       "userid            21569\n",
       "refund_txnid      21569\n",
       "checkoutid        21569\n",
       "type              21569\n",
       "amount            21569\n",
       "currency          21569\n",
       "channelid         21569\n",
       "status            21569\n",
       "channel_status    21569\n",
       "channel_txnid     21569\n",
       "ip                21569\n",
       "action_country    21569\n",
       "ctime             21569\n",
       "vtime             21569\n",
       "mtime             21569\n",
       "memo              21569\n",
       "extra_data        21569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many records in this df?\n",
    "orders.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change to a more large dataset\n",
    "DB_URL = \"mysql://%s:%s@%s:%s/%s\" % ('secret')\n",
    "engine = create_engine(DB_URL)\n",
    "records = pd.read_sql('select * from xx_realtime',\n",
    "                 con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.8321533203125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_size(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          367704\n",
       "type        367704\n",
       "date        367704\n",
       "tick        367704\n",
       "location    367704\n",
       "data        367704\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load as string? how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_URL = \"mysql://%s:%s@%s:%s/%s::airpay_daily\" % ('secret')\n",
    "stats = Data(DB_URL)\n",
    "data = stats[\n",
    "            (stats.type==4) & (stats.date == '20150726') & (\n",
    "            stats.location =='TH') & (stats.extra=='Total')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>extra</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8624</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>TH</td>\n",
       "      <td>Total</td>\n",
       "      <td>{\"txn_user\": 4147, \"txn_value\": 1895538.140000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "     id  type        date location  extra  \\\n",
       "0  8624     4  2015-07-26       TH  Total   \n",
       "\n",
       "                                                data  \n",
       "0  {\"txn_user\": 4147, \"txn_value\": 1895538.140000...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[0].data\n",
    "\n",
    "# seems cannot get the data value like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use odo conver blaze object to pandas df\n",
    "from odo import odo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = odo(data, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>extra</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8624</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>TH</td>\n",
       "      <td>Total</td>\n",
       "      <td>{\"txn_user\": 4147, \"txn_value\": 1895538.140000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  type        date location  extra  \\\n",
       "0  8624     4  2015-07-26       TH  Total   \n",
       "\n",
       "                                                data  \n",
       "0  {\"txn_user\": 4147, \"txn_value\": 1895538.140000...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"txn_user\": 4147, \"txn_value\": 1895538.1400000025, \"txn_num\": 5512}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[0]['data']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.loads(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas read_csv()\n",
    "其实很多时候已经够用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_path = 'data/test.20150927'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 1296, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-14e8fec1d1a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 日常read_csv最常用的几个参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# sep：指定数据列间隔的标志\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# header：指定第一行是否为列名，一般情况下如果读的是原始log数据，这个会设置成None，要不然默认会把文件的第一行作为列明，从而少了一行数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# usecols: 读入的时候就能指定自己需要的数据在哪些列，免去了事后操作的麻烦，同时减少内存的不必要使用\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m _parser_defaults = {\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    719\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skip_footer not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas\\parser.c:7544)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas\\parser.c:7784)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas\\parser.c:8401)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas\\parser.c:8275)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas\\parser.c:20691)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 4 fields in line 1296, saw 5\n"
     ]
    }
   ],
   "source": [
    "log = pd.read_csv(log_path, sep='|', header=None, usecols=[3,])\n",
    "# 日常read_csv最常用的几个参数\n",
    "# sep：指定数据列间隔的标志\n",
    "# header：指定第一行是否为列名，一般情况下如果读的是原始log数据，这个会设置成None，要不然默认会把文件的第一行作为列明，从而少了一行数据\n",
    "# usecols: 读入的时候就能指定自己需要的数据在哪些列，免去了事后操作的麻烦，同时减少内存的不必要使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以上， 原始log的格式不是每一行都是规范的，因此在读的时候有可能出现有毛病的行；\n",
    "# 例如这个例子就是某些行的列数比其他行多，因而出错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/var/home/ftp/im_log/80.175/info.log.20150927.23:2015-09-27 23:23:58.898|INFO|user_auth_game_sent_aux|uid=9278794,client_type=3,appid=100022,redirect_uri=gop100022://auth/,scope=,ip=103.1.69.2`\n",
    "\n",
    "\n",
    "`/var/home/ftp/im_log/80.176/info.log.20150927.00:2015-09-27 00:01:16.929|INFO|0x00000154|user_auth_game_sent_aux|uid=71097840,client_type=3,appid=100022,redirect_uri=gop100022://auth/,scope=,ip=49.144.236.127`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 1296: expected 4 fields, saw 5\n",
      "Skipping line 1297: expected 4 fields, saw 5\n",
      "Skipping line 1298: expected 4 fields, saw 5\n",
      "Skipping line 1299: expected 4 fields, saw 5\n",
      "Skipping line 1300: expected 4 fields, saw 5\n",
      "Skipping line 1301: expected 4 fields, saw 5\n",
      "Skipping line 1302: expected 4 fields, saw 5\n",
      "Skipping line 1303: expected 4 fields, saw 5\n",
      "Skipping line 1304: expected 4 fields, saw 5\n",
      "Skipping line 1305: expected 4 fields, saw 5\n",
      "Skipping line 1306: expected 4 fields, saw 5\n",
      "Skipping line 1307: expected 4 fields, saw 5\n",
      "Skipping line 1308: expected 4 fields, saw 5\n",
      "Skipping line 1309: expected 4 fields, saw 5\n",
      "Skipping line 1310: expected 4 fields, saw 5\n",
      "Skipping line 1311: expected 4 fields, saw 5\n",
      "Skipping line 1312: expected 4 fields, saw 5\n",
      "Skipping line 1313: expected 4 fields, saw 5\n",
      "Skipping line 1314: expected 4 fields, saw 5\n",
      "Skipping line 1315: expected 4 fields, saw 5\n",
      "Skipping line 1316: expected 4 fields, saw 5\n",
      "Skipping line 1317: expected 4 fields, saw 5\n",
      "Skipping line 1318: expected 4 fields, saw 5\n",
      "Skipping line 1319: expected 4 fields, saw 5\n",
      "Skipping line 1320: expected 4 fields, saw 5\n",
      "Skipping line 1321: expected 4 fields, saw 5\n",
      "Skipping line 1322: expected 4 fields, saw 5\n",
      "Skipping line 1323: expected 4 fields, saw 5\n",
      "Skipping line 1324: expected 4 fields, saw 5\n",
      "Skipping line 1325: expected 4 fields, saw 5\n",
      "Skipping line 1326: expected 4 fields, saw 5\n",
      "Skipping line 1327: expected 4 fields, saw 5\n",
      "Skipping line 1328: expected 4 fields, saw 5\n",
      "Skipping line 1329: expected 4 fields, saw 5\n",
      "Skipping line 1330: expected 4 fields, saw 5\n",
      "Skipping line 1331: expected 4 fields, saw 5\n",
      "Skipping line 1332: expected 4 fields, saw 5\n",
      "Skipping line 1333: expected 4 fields, saw 5\n",
      "Skipping line 1334: expected 4 fields, saw 5\n",
      "Skipping line 1335: expected 4 fields, saw 5\n",
      "Skipping line 1336: expected 4 fields, saw 5\n",
      "Skipping line 1337: expected 4 fields, saw 5\n",
      "Skipping line 1338: expected 4 fields, saw 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 上面的第二行是有问题的数据\n",
    "log = pd.read_csv(log_path, sep='|', header=None, usecols=[3,], error_bad_lines=False)\n",
    "# 增加新参数\n",
    "# error_bad_lines=False 遇到错误的行自动忽略\n",
    "# 这里就涉及到pandas的其中一个坑的，万一第一条log就命中了错误格式的log的话，所以正常的数据都会被视为是错误的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以上， 增加参数后能正常读入原始log\n",
    "# 每行有问题的log会报警给我们看\n",
    "log = pd.read_csv(log_path, sep='|', header=None, usecols=[3,], error_bad_lines=False, warn_bad_lines=False)\n",
    "# 新增参数，可以忽略这些报警\n",
    "# warn_bad_lines=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log.columns = ['data']\n",
    "# 读入的关键数据只在一列，同时要将这一列数据分解成多列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uid=89331925,client_type=3,appid=100022,redire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uid=140220082,client_type=3,appid=100022,redir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uid=225503167,client_type=3,appid=100022,redir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uid=91462520,client_type=3,appid=100022,redire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uid=68544100,client_type=3,appid=100022,redire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  uid=89331925,client_type=3,appid=100022,redire...\n",
       "1  uid=140220082,client_type=3,appid=100022,redir...\n",
       "2  uid=225503167,client_type=3,appid=100022,redir...\n",
       "3  uid=91462520,client_type=3,appid=100022,redire...\n",
       "4  uid=68544100,client_type=3,appid=100022,redire..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 参考 Working with Text Data.ipynb\n",
    "# expand=True\n",
    "log = log.data.str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uid=89331925</td>\n",
       "      <td>client_type=3</td>\n",
       "      <td>appid=100022</td>\n",
       "      <td>redirect_uri=gop100022://auth/</td>\n",
       "      <td>scope=</td>\n",
       "      <td>ip=180.191.151.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uid=140220082</td>\n",
       "      <td>client_type=3</td>\n",
       "      <td>appid=100022</td>\n",
       "      <td>redirect_uri=gop100022://auth/</td>\n",
       "      <td>scope=</td>\n",
       "      <td>ip=112.202.113.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uid=225503167</td>\n",
       "      <td>client_type=3</td>\n",
       "      <td>appid=100022</td>\n",
       "      <td>redirect_uri=gop100022://auth/</td>\n",
       "      <td>scope=</td>\n",
       "      <td>ip=223.205.76.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uid=91462520</td>\n",
       "      <td>client_type=3</td>\n",
       "      <td>appid=100022</td>\n",
       "      <td>redirect_uri=gop100022://auth/</td>\n",
       "      <td>scope=</td>\n",
       "      <td>ip=103.43.150.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uid=68544100</td>\n",
       "      <td>client_type=3</td>\n",
       "      <td>appid=100022</td>\n",
       "      <td>redirect_uri=gop100022://auth/</td>\n",
       "      <td>scope=</td>\n",
       "      <td>ip=115.66.211.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0              1             2                               3  \\\n",
       "0   uid=89331925  client_type=3  appid=100022  redirect_uri=gop100022://auth/   \n",
       "1  uid=140220082  client_type=3  appid=100022  redirect_uri=gop100022://auth/   \n",
       "2  uid=225503167  client_type=3  appid=100022  redirect_uri=gop100022://auth/   \n",
       "3   uid=91462520  client_type=3  appid=100022  redirect_uri=gop100022://auth/   \n",
       "4   uid=68544100  client_type=3  appid=100022  redirect_uri=gop100022://auth/   \n",
       "\n",
       "        4                   5  \n",
       "0  scope=  ip=180.191.151.126  \n",
       "1  scope=   ip=112.202.113.96  \n",
       "2  scope=    ip=223.205.76.44  \n",
       "3  scope=   ip=103.43.150.138  \n",
       "4  scope=   ip=115.66.211.118  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UTF8 处理\n",
    "当源数据涉及到其他非英文语言的时候，读取数据的时候最好加上编码信息；\n",
    "\n",
    "否则在后面处理的时候会各种出现乱码问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 先看看read_csv的编码设置\n",
    "\n",
    "encoding : string, default **None**\n",
    "\n",
    "\n",
    "Encoding to use for UTF when reading/writing (ex. ‘utf-8’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chinese_file = 'data/Chinese.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv(chinese_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>����</th>\n",
       "      <th>����</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>��ΰ��</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ����  ����\n",
       "0  ��ΰ��    60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 以上，没有设定encoding参数的情况下\n",
    "raw = pd.read_csv(chinese_file, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>姓名</th>\n",
       "      <th>分数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>温伟坤</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    姓名  分数\n",
       "0  温伟坤  60"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-44d9df1ed875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/test_chinese_output'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                                      \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                                      decimal=decimal)\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\core\\format.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\core\\format.pyc\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wen Weikun\\Anaconda\\lib\\site-packages\\pandas\\core\\format.pyc\u001b[0m in \u001b[0;36m_save_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m         \u001b[1;31m# write out the index label line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "output = 'data/test_chinese_output'\n",
    "raw.to_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以上，不能直接output\n",
    "# 需要带上编码信息\n",
    "raw.to_csv(output, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'姓名', u'分数'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns\n",
    "# 计算及应用过程都将使用Unicode来进行\n",
    "# 只在过程的两端使用encode  utf8--Unicode--utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60\n",
       "Name: 分数, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    温伟坤\n",
       "Name: 姓名, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 从DB中读数据的编码问题\n",
    "这里需要结合sqlalchemy的编码设置,因为pandas依赖sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在URL后加入\n",
    "\n",
    "\n",
    "`?charset=utf8`\n",
    "\n",
    "参考："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_app_df():\n",
    "    DB_URL = \"mysql://%s:%s@%s:%s/%s?charset=utf8\" % (APP_DB['user'], APP_DB['psw'], APP_DB['host'], APP_DB['port'], APP_DB['name'])\n",
    "    engine = create_engine(DB_URL)\n",
    "    df = pd.read_sql('select app_id, app_name from %s ' % 'app_tab', con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
